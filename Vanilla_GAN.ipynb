{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EngBaz/Generative-AI-GANs/blob/main/Vanilla_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y2Pn8P2Lw1Q"
      },
      "source": [
        "# CONNECT TO GOOGLE DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY3G6qmvL8Gu",
        "outputId": "ddb25389-f38d-49ec-81a0-87d627a2a843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys    \n",
        "path_to_module = '/content/gdrive/MyDrive/Assignment_2_Generative_models'\n",
        "sys.path.append(path_to_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-reyzOYzHnkB"
      },
      "source": [
        "#IMPORT THE NECESSARY LIBRARIES\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ekGX544pHjWM"
      },
      "outputs": [],
      "source": [
        "#Prerequisites\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "#Device configuration\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#THE GENERATOR AND DISCRIMINATOR NETWORK"
      ],
      "metadata": {
        "id": "T0cRGbqPvTXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator_Dense(nn.Module):\n",
        "    def __init__(self, g_latent_input_dim, g_hidden_dim, g_output_dim,use_batch_norm=False):\n",
        "      super(Generator_Dense, self).__init__()\n",
        "      self.linear_1 = nn.Linear(g_latent_input_dim, g_hidden_dim)\n",
        "      self.linear_2 = nn.Linear(g_hidden_dim, g_hidden_dim)\n",
        "      self.linear_3 = nn.Linear(g_hidden_dim, g_output_dim)\n",
        "\n",
        "      self.use_batch_norm = use_batch_norm\n",
        "\n",
        "      self.bnorm1 = nn.BatchNorm1d(g_hidden_dim)\n",
        "      self.bnorm2 = nn.BatchNorm1d(g_output_dim)\n",
        "\n",
        "      self.activation_for_hidden = nn.PReLU()\n",
        "      self.activation_for_last = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.linear_1(x)\n",
        "      if self.use_batch_norm:\n",
        "        x = self.bnorm1(x)\n",
        "      x = self.activation_for_hidden(x)\n",
        "      x = self.linear_2(x)\n",
        "      if self.use_batch_norm:\n",
        "        x = self.bnorm1(x)\n",
        "      x = self.activation_for_hidden(x)\n",
        "      x = self.linear_2(x)\n",
        "      if self.use_batch_norm:\n",
        "        x = self.bnorm1(x)\n",
        "      x = self.activation_for_hidden(x)\n",
        "      x = self.linear_3(x)\n",
        "      if self.use_batch_norm:\n",
        "        x = self.bnorm2(x)\n",
        "      x = self.activation_for_last(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "class Discriminator_Dense(torch.nn.Module):\n",
        "      def __init__(self, image_size, hidden_size,use_batch_norm=False):\n",
        "        super(Discriminator_Dense, self).__init__()\n",
        "        self.linear_1 = nn.Linear(image_size, hidden_size)\n",
        "        self.linear_2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear_3 = nn.Linear(hidden_size, 1)\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "        self.bnorm1 = nn.BatchNorm1d(hidden_size)\n",
        "        self.activation_for_hidden = nn.LeakyReLU(0.2)\n",
        "        self.activation_for_last = nn.Sigmoid()\n",
        "\n",
        "      def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        if self.use_batch_norm:\n",
        "          x = self.bnorm1(x)\n",
        "        x = self.activation_for_hidden(x)\n",
        "        x = self.linear_2(x)\n",
        "        if self.use_batch_norm:\n",
        "          x = self.bnorm1(x)\n",
        "        x = self.activation_for_hidden(x)\n",
        "        x = self.linear_2(x)\n",
        "        if self.use_batch_norm:\n",
        "          x = self.bnorm1(x)\n",
        "        x = self.activation_for_hidden(x)\n",
        "        x = self.linear_3(x)\n",
        "        x = self.activation_for_last(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cOc0bcmBn9fI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6aoXAuhoyuF"
      },
      "source": [
        "#HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wyrCIA11ox0W"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "latent_size = 128\n",
        "hidden_size = 256\n",
        "image_size = 784\n",
        "num_epochs = 5\n",
        "batch_size = 32\n",
        "save_dir = f'/content/gdrive/MyDrive/Assignment_2_Generative_models/dense_network/models_{latent_size}'\n",
        "generated_images_dir = save_dir + '/generated/'\n",
        "sample_dir = save_dir + '/saples/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0CaWZffo65e"
      },
      "source": [
        "#CREATE DIRECTORIES IF THEY DON'T EXIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VmToGh9ho_xA"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(sample_dir):\n",
        "    os.makedirs(sample_dir)\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "if not os.path.exists(generated_images_dir):\n",
        "    os.makedirs(generated_images_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cwi7goaH0Hl"
      },
      "source": [
        "#READ THE DATASET\n",
        "\n",
        "When reading the dataset, we imediatelly do two things:\n",
        "\n",
        "\n",
        "1.   Convert the image to tensor\n",
        "2.   Normalize image to have 0 mean and 1 standard deviation\n",
        "\n",
        "We use a batchsize of 32."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eVZQ9Jc3HmX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ca2ad3-03a1-4821-c7ce-db25b7bfde2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 165785593.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 41160616.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 66078341.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7833276.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Image processing\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=(0.5),   # 3 for RGB channels\n",
        "                                     std=(0.5)),\n",
        "                ])\n",
        "\n",
        "#Reading the dataset\n",
        "mnist = torchvision.datasets.MNIST(root='./data/',\n",
        "                                   transform=transform,\n",
        "                                   download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEyy1WxIYcu"
      },
      "source": [
        "#CREATE A DATALOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IOZLkqcJqAWr"
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzPFtXJVMrs8"
      },
      "source": [
        "# DEFINE THE GENERATOR AND DISCRIMINATOR MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AQrocOY4pozr"
      },
      "outputs": [],
      "source": [
        "D = Discriminator_Dense(image_size,hidden_size)\n",
        "G = Generator_Dense(latent_size,hidden_size,image_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vi34QwxpscD"
      },
      "source": [
        "#MOVE THE GENERATOR AND DISCRIMINATOR TO GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xNVaYthoIXNB"
      },
      "outputs": [],
      "source": [
        "D = D.to(device)\n",
        "G = G.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96f4ak3jN1pZ"
      },
      "source": [
        "#DEFINE THE OPTIMIZER AND THE LOSS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aoWOs_XLpv3w"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss()\n",
        "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjIQXzvaOXM2"
      },
      "source": [
        "# TRAINING LOOP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIUKR6NDqPRC"
      },
      "source": [
        "Before going in the the main training loop we need to define some utility functions:\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKsKEtWIquGr"
      },
      "source": [
        "Here we define the opposite of the normalization, remember that when we first read the dataset, we normalized it (mean=0, std =1), now we do the opposite so that when saving the images we get the correct image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xKfgo5vjqoXg"
      },
      "outputs": [],
      "source": [
        "def denorm(x):\n",
        "    out = (x + 1) / 2\n",
        "    return out.clamp(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSF7Xb4Wqol3"
      },
      "source": [
        "In PyTorch, for every mini-batch during the training phase, we typically want to explicitly set the gradients to zero before starting to do backpropragation (i.e., updating the weights and biases) because PyTorch accumulates the gradients on subsequent backward passes. This accumulating behaviour is convenient while training RNNs or when we want to compute the gradient of the loss summed over multiple mini-batches. So, the default action has been set to accumulate (i.e. sum) the gradients on every loss.backward() call.\n",
        "\n",
        "Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly. Otherwise, the gradient would be a combination of the old gradient, which you have already used to update your model parameters, and the newly-computed gradient. It would therefore point in some other direction than the intended direction towards the minimum (or maximum, in case of maximization objectives)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Tzbuvmg2qrir"
      },
      "outputs": [],
      "source": [
        "def reset_grad():\n",
        "    d_optimizer.zero_grad()\n",
        "    g_optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swjxbwl-rLSb"
      },
      "source": [
        "Next, we define NumPy arrays for saving the losses and scores, they are initially zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WPmjAuyrqWHs"
      },
      "outputs": [],
      "source": [
        "d_losses = np.zeros(num_epochs)\n",
        "g_losses = np.zeros(num_epochs)\n",
        "real_scores = np.zeros(num_epochs)\n",
        "fake_scores = np.zeros(num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGH5p8xira6W"
      },
      "source": [
        "# The `Training` loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "btJK2lMP6Zww"
      },
      "outputs": [],
      "source": [
        "def generate_images(generator_model_dir,number_of_images,save_dir,latent_size = 64,save_combined=False):\n",
        "\n",
        "  #Loading pretrained model from the drive directory\n",
        "  if torch.cuda.is_available():\n",
        "    G = torch.jit.load(generator_model_dir,map_location='cuda')\n",
        "    G.to(device)\n",
        "  else:\n",
        "    G = torch.jit.load(generator_model_dir,map_location='cpu')\n",
        "\n",
        "  G.eval()\n",
        "\n",
        "  #Generating random noise to pass it to the Generator\n",
        "  z = torch.randn(number_of_images, latent_size).to(device)\n",
        "  z = Variable(z)\n",
        "\n",
        "  #Creating fake images from the distribution\n",
        "  fake_images = G(z)\n",
        "  fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "  \n",
        "\n",
        "  #Save sampled images\n",
        "  fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "  #Save_image(denorm(fake_images.data), os.path.join(save_dir, 'fake_images-{i}.png'))\n",
        "  if save_combined:\n",
        "    torchvision.utils.save_image(denorm(fake_images.data), f'{save_dir}/combined.png')\n",
        "  for i in range(fake_images.size(0)):\n",
        "           torchvision.utils.save_image(denorm(fake_images.data)[i, :, :, :], f'{save_dir}/{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4xwrpm-AORbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede87b15-dcf4-4e98-ccd4-9d6e499431b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/5], Step [200/1875], d_loss: 0.8771, g_loss: 2.2448, D(x): 0.70, D(G(z)): 0.27\n",
            "Epoch [0/5], Step [400/1875], d_loss: 0.3744, g_loss: 3.8256, D(x): 0.87, D(G(z)): 0.16\n",
            "Epoch [0/5], Step [600/1875], d_loss: 0.0497, g_loss: 5.3526, D(x): 0.98, D(G(z)): 0.03\n",
            "Epoch [0/5], Step [800/1875], d_loss: 0.6924, g_loss: 2.7342, D(x): 0.70, D(G(z)): 0.18\n",
            "Epoch [0/5], Step [1000/1875], d_loss: 0.2765, g_loss: 5.0606, D(x): 0.93, D(G(z)): 0.16\n",
            "Epoch [0/5], Step [1200/1875], d_loss: 0.7874, g_loss: 4.8226, D(x): 0.80, D(G(z)): 0.26\n",
            "Epoch [0/5], Step [1400/1875], d_loss: 2.2872, g_loss: 1.0852, D(x): 0.38, D(G(z)): 0.50\n",
            "Epoch [0/5], Step [1600/1875], d_loss: 1.7313, g_loss: 1.7404, D(x): 0.47, D(G(z)): 0.30\n",
            "Epoch [0/5], Step [1800/1875], d_loss: 1.4655, g_loss: 1.3718, D(x): 0.65, D(G(z)): 0.56\n",
            "Epoch [1/5], Step [200/1875], d_loss: 0.1629, g_loss: 3.1403, D(x): 0.96, D(G(z)): 0.11\n",
            "Epoch [1/5], Step [400/1875], d_loss: 0.8977, g_loss: 1.9031, D(x): 0.68, D(G(z)): 0.34\n",
            "Epoch [1/5], Step [600/1875], d_loss: 1.1515, g_loss: 1.6586, D(x): 0.66, D(G(z)): 0.30\n",
            "Epoch [1/5], Step [800/1875], d_loss: 0.3916, g_loss: 2.6629, D(x): 0.88, D(G(z)): 0.14\n",
            "Epoch [1/5], Step [1000/1875], d_loss: 1.1055, g_loss: 1.3267, D(x): 0.56, D(G(z)): 0.26\n",
            "Epoch [1/5], Step [1200/1875], d_loss: 0.3074, g_loss: 2.5676, D(x): 0.94, D(G(z)): 0.18\n",
            "Epoch [1/5], Step [1400/1875], d_loss: 0.9921, g_loss: 1.3513, D(x): 0.64, D(G(z)): 0.32\n",
            "Epoch [1/5], Step [1600/1875], d_loss: 0.5110, g_loss: 2.8727, D(x): 0.72, D(G(z)): 0.04\n",
            "Epoch [1/5], Step [1800/1875], d_loss: 0.3610, g_loss: 2.3239, D(x): 0.84, D(G(z)): 0.14\n",
            "Epoch [2/5], Step [200/1875], d_loss: 0.4102, g_loss: 2.1280, D(x): 0.83, D(G(z)): 0.15\n",
            "Epoch [2/5], Step [400/1875], d_loss: 0.6735, g_loss: 1.5383, D(x): 0.82, D(G(z)): 0.26\n",
            "Epoch [2/5], Step [600/1875], d_loss: 0.3018, g_loss: 4.5369, D(x): 0.85, D(G(z)): 0.02\n",
            "Epoch [2/5], Step [800/1875], d_loss: 0.1066, g_loss: 5.0539, D(x): 0.97, D(G(z)): 0.06\n",
            "Epoch [2/5], Step [1000/1875], d_loss: 2.2570, g_loss: 0.9068, D(x): 0.46, D(G(z)): 0.44\n",
            "Epoch [2/5], Step [1200/1875], d_loss: 0.6228, g_loss: 1.8125, D(x): 0.86, D(G(z)): 0.26\n",
            "Epoch [2/5], Step [1400/1875], d_loss: 0.8625, g_loss: 1.3543, D(x): 0.78, D(G(z)): 0.37\n",
            "Epoch [2/5], Step [1600/1875], d_loss: 0.3579, g_loss: 2.7846, D(x): 0.90, D(G(z)): 0.17\n",
            "Epoch [2/5], Step [1800/1875], d_loss: 0.8520, g_loss: 1.4886, D(x): 0.77, D(G(z)): 0.19\n",
            "Epoch [3/5], Step [200/1875], d_loss: 0.8608, g_loss: 1.9788, D(x): 0.77, D(G(z)): 0.19\n",
            "Epoch [3/5], Step [400/1875], d_loss: 0.9587, g_loss: 3.0511, D(x): 0.77, D(G(z)): 0.28\n",
            "Epoch [3/5], Step [600/1875], d_loss: 1.2402, g_loss: 2.1035, D(x): 0.87, D(G(z)): 0.51\n",
            "Epoch [3/5], Step [800/1875], d_loss: 0.5777, g_loss: 4.2809, D(x): 0.90, D(G(z)): 0.30\n",
            "Epoch [3/5], Step [1000/1875], d_loss: 1.0350, g_loss: 2.6818, D(x): 0.68, D(G(z)): 0.16\n",
            "Epoch [3/5], Step [1200/1875], d_loss: 0.8596, g_loss: 1.7930, D(x): 0.79, D(G(z)): 0.30\n",
            "Epoch [3/5], Step [1400/1875], d_loss: 0.5399, g_loss: 2.1607, D(x): 0.85, D(G(z)): 0.19\n",
            "Epoch [3/5], Step [1600/1875], d_loss: 0.7949, g_loss: 2.2771, D(x): 0.94, D(G(z)): 0.35\n",
            "Epoch [3/5], Step [1800/1875], d_loss: 0.3778, g_loss: 2.4509, D(x): 0.86, D(G(z)): 0.12\n",
            "Epoch [4/5], Step [200/1875], d_loss: 0.2613, g_loss: 7.1802, D(x): 0.92, D(G(z)): 0.09\n",
            "Epoch [4/5], Step [400/1875], d_loss: 0.1881, g_loss: 8.2707, D(x): 0.92, D(G(z)): 0.07\n",
            "Epoch [4/5], Step [600/1875], d_loss: 0.1653, g_loss: 3.8049, D(x): 0.95, D(G(z)): 0.09\n",
            "Epoch [4/5], Step [800/1875], d_loss: 0.1807, g_loss: 4.3059, D(x): 0.94, D(G(z)): 0.09\n",
            "Epoch [4/5], Step [1000/1875], d_loss: 0.2067, g_loss: 3.3209, D(x): 0.91, D(G(z)): 0.08\n",
            "Epoch [4/5], Step [1200/1875], d_loss: 0.4102, g_loss: 2.3423, D(x): 0.86, D(G(z)): 0.11\n",
            "Epoch [4/5], Step [1400/1875], d_loss: 0.4804, g_loss: 2.3023, D(x): 0.86, D(G(z)): 0.09\n",
            "Epoch [4/5], Step [1600/1875], d_loss: 0.2991, g_loss: 3.8715, D(x): 0.90, D(G(z)): 0.12\n",
            "Epoch [4/5], Step [1800/1875], d_loss: 0.3105, g_loss: 3.4490, D(x): 0.95, D(G(z)): 0.17\n"
          ]
        }
      ],
      "source": [
        "total_step = len(data_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, _) in enumerate(data_loader):\n",
        "        images = images.view(batch_size, -1).to(device)\n",
        "        images = Variable(images)\n",
        "        #Create the labels which are later used as input for the BCE loss\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        real_labels = Variable(real_labels)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "        fake_labels = Variable(fake_labels)\n",
        "\n",
        "       \n",
        "        #Train Discriminator\n",
        "        #Compute BCE_Loss using real images where BCE_Loss(x, y) = - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
        "        #Second term of the loss is always zero since real_labels == 1\n",
        "        outputs = D(images)\n",
        "        d_loss_real = criterion(outputs, real_labels)\n",
        "        real_score = outputs\n",
        "        \n",
        "        #Compute BCELoss using fake images\n",
        "        #First term of the loss is always zero since fake_labels == 0\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        z = Variable(z)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        d_loss_fake = criterion(outputs, fake_labels)\n",
        "        fake_score = outputs\n",
        "        \n",
        "        #If D is trained very well, then don't update\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        reset_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "\n",
        "        #Training the Generator\n",
        "        #Compute loss with fake images\n",
        "        z = torch.randn(batch_size, latent_size).to(device)\n",
        "        z = Variable(z)\n",
        "        fake_images = G(z)\n",
        "        outputs = D(fake_images)\n",
        "        \n",
        "        #Train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "        \n",
        "  \n",
        "        reset_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "\n",
        "        #Adding the losses and scores to the predefind NumPy arrays\n",
        "        d_losses[epoch] = d_losses[epoch]*(i/(i+1.)) + d_loss.data*(1./(i+1.))\n",
        "        g_losses[epoch] = g_losses[epoch]*(i/(i+1.)) + g_loss.data*(1./(i+1.))\n",
        "        real_scores[epoch] = real_scores[epoch]*(i/(i+1.)) + real_score.mean().data*(1./(i+1.))\n",
        "        fake_scores[epoch] = fake_scores[epoch]*(i/(i+1.)) + fake_score.mean().data*(1./(i+1.))\n",
        "        \n",
        "        if (i+1) % 200 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "                  .format(epoch, num_epochs, i+1, total_step, d_loss.data, g_loss.data, \n",
        "                          real_score.mean().data, fake_score.mean().data))\n",
        "    \n",
        "    #Save real images\n",
        "    if (epoch+1) == 10:\n",
        "        images = images.view(images.size(0), 1, 28, 28)\n",
        "        save_image(denorm(images.data), os.path.join(sample_dir, 'real_images.png'))\n",
        "    \n",
        "    #Save sampled images\n",
        "    fake_images = fake_images.view(fake_images.size(0), 1, 28, 28)\n",
        "    save_image(denorm(fake_images.data), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
        "    \n",
        "    #Save and plot statistics\n",
        "    np.save(os.path.join(save_dir, 'd_losses.npy'), d_losses)\n",
        "    np.save(os.path.join(save_dir, 'g_losses.npy'), g_losses)\n",
        "    np.save(os.path.join(save_dir, 'fake_scores.npy'), fake_scores)\n",
        "    np.save(os.path.join(save_dir, 'real_scores.npy'), real_scores)\n",
        "    \n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    plt.plot(range(1, num_epochs + 1), d_losses, label='d loss')\n",
        "    plt.plot(range(1, num_epochs + 1), g_losses, label='g loss')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'loss.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    pylab.xlim(0, num_epochs + 1)\n",
        "    pylab.ylim(0, 1)\n",
        "    plt.plot(range(1, num_epochs + 1), fake_scores, label='fake score')\n",
        "    plt.plot(range(1, num_epochs + 1), real_scores, label='real score')    \n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(save_dir, 'accuracy.pdf'))\n",
        "    plt.close()\n",
        "\n",
        "    #Save the model at checkpoints\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        G_scripted = torch.jit.script(G) # Export to TorchScript\n",
        "        G_scripted.save(os.path.join(save_dir, 'G_scripted_{}.pt'.format(epoch+1)))\n",
        "        D_scripted = torch.jit.script(D) # Export to TorchScript\n",
        "        D_scripted.save(os.path.join(save_dir, 'D_scripted_{}.pt'.format(epoch+1)))\n",
        "\n",
        "\n",
        "        generate_images(os.path.join(save_dir, 'G_scripted_{}.pt'.format(epoch+1)),batch_size, generated_images_dir, latent_size = latent_size)\n",
        "\n",
        "        torch.save(G.state_dict(), os.path.join(save_dir, 'G--{}.ckpt'.format(epoch+1)))\n",
        "        torch.save(D.state_dict(), os.path.join(save_dir, 'D--{}.ckpt'.format(epoch+1)))\n",
        "\n",
        "#Save the model checkpoints \n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lH33orAl-zL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}